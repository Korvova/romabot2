// webapp/src/App.jsx
import { useRef, useState } from 'react';
import { initWakeListener } from './wakeListener.js';
import './index.css';

const pendingCallRef = { current: null };
const SLEEP_KEYWORDS = ['Ñ€Ğ¾Ğ¼Ğ° ÑĞ¿ÑÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼', 'Ñ€Ğ¾Ğ¼Ğ° ÑĞ¿Ğ¸', 'roma sleep'];

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  1) Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ğ°: Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ QRâ€‘ĞºĞ¾Ğ´
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
function showQr(src = '/2/qr.png', ms = 10_000) {
  const img = document.getElementById('qr-img');
  if (!img) return;
  img.src = src;
  img.style.display = 'block';
  setTimeout(() => { img.style.display = 'none'; }, ms);
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  2) Ğ’ÑÑ‚Ñ€Ğ¾ĞµĞ½Ğ½Ñ‹Ğµ toolâ€‘handlers
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
const builtinHandlers = {
  show_qr_code: ({ qrUrl }) => {
    const url = qrUrl?.startsWith('/2/') ? qrUrl : `/2${qrUrl || '/qr.png'}`;
    showQr(url);
    return { ok: true };
  },

  // ğŸ’¤ ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ° Ğ² ÑĞ¿ÑÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
  stop_roma: () => {
    if (typeof window.pauseRoma === 'function') {
      window.pauseRoma();
      console.log('ğŸ›Œ stop_roma: Roma is sleeping');
      return { ok: true };
    }
    console.warn('stop_roma: pauseRoma is not ready');
    return { ok: false, error: 'not_ready' };
  }
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  3) Ğ’Ñ‹Ğ·Ğ¾Ğ² ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ğ½Ğ¸Ñ… Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¹ (admin tools)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
async function runTool(name, args, tools) {
  if (builtinHandlers[name]) return builtinHandlers[name](args);

  const fn = tools.find(f => f.name === name);
  if (!fn?.meta?.endpoint) throw new Error(`Function ${name} has no endpoint`);

  const res = await fetch(fn.meta.endpoint, {
    method : fn.meta.method || 'GET',
    headers: { 'Content-Type': 'application/json' },
    body   : fn.meta.method === 'POST' ? JSON.stringify(args) : undefined
  });
  return res.json();
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  4) Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ function_call
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
async function finishCall(dc, tools) {
  const call = pendingCallRef.current;
  if (!call) return;

  try {
    const json   = call.args.join('');
    const args   = json ? JSON.parse(json) : {};
    const output = await runTool(call.name, args, tools);

    dc.send(JSON.stringify({
      type: 'conversation.item.create',
      item: {
        type   : 'function_call_output',
        call_id: call.call_id,
        output : JSON.stringify(output)
      }
    }));
    dc.send(JSON.stringify({ type: 'response.create' }));
  } catch (e) {
    console.error('finishCall error', e);
  } finally {
    pendingCallRef.current = null;
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 *  5) Reactâ€‘ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
export default function App() {
  const [log, setLog]         = useState([]);
  const [started, setStarted] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [hidden, setHidden]   = useState(false);   // â† Ğ½Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ


  const pcRef     = useRef(null);
  const dcRef     = useRef(null);
  const wsRef     = useRef(null);
  const audioRef  = useRef(null);
  const senderRef = useRef(null);   // RTCRtpSender (audio)
  const wakeRef   = useRef(null);   // Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ wakeâ€‘listener

  const addLog = txt => setLog(prev => [...prev, txt]);

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   *  ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ²: pause / resume
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
  let sleeping = false;          // Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ

  const pauseRealtime = () => {
    if (sleeping) {
      addLog('ğŸŸ¡ Already sleeping');
      return;
    }
    if (!senderRef.current) {
      addLog('âš ï¸ pauseRealtime: sender not ready');
      return;
    }
    sleeping = true;

    // â›” Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ Ğ°ÑƒĞ´Ğ¸Ğ¾
    const oldTrack = senderRef.current.track;
    try {
      senderRef.current.replaceTrack(null);
      addLog('ğŸ”‡ RTP stream muted (replaceTrack â†’ null)');
      oldTrack && oldTrack.stop();
      addLog('ğŸ›‘ Old mic track stopped');
    } catch (e) {
      addLog(`âŒ pauseRealtime error: ${e.message}`);
    }

    // ğŸ‘‚ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ wakeâ€‘listener
    if (!wakeRef.current) {
      wakeRef.current = initWakeListener({
        lang  : 'ru-RU',
        onWake: resumeRealtime
      });
      addLog('ğŸ‘‚ Wakeâ€‘listener started â€” Ğ¶Ğ´Ñ‘Ğ¼ ÑĞ»Ğ¾Ğ²Ğ¾ Â«Ñ€Ğ¾Ğ¼Ğ°Â»');
    }
  };

  const resumeRealtime = async () => {
    if (!sleeping) {
      addLog('ğŸŸ¢ Already awake');
      return;
    }
    sleeping = false;

    // 1) Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ wakeâ€‘listener
    if (wakeRef.current) {
      wakeRef.current.stop();
      wakeRef.current = null;
      addLog('ğŸ”• Wakeâ€‘listener stopped');
    }

    // 2) Ğ¿Ñ€Ğ¸ĞºÑ€ĞµĞ¿Ğ¸Ñ‚ÑŒ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ‚Ñ€ĞµĞº
    try {
      const stream   = await navigator.mediaDevices.getUserMedia({ audio: true });
      const newTrack = stream.getAudioTracks()[0];
      await senderRef.current.replaceTrack(newTrack);
      addLog('ğŸ¤ New mic track attached (resume realâ€‘time)');
    } catch (e) {
      addLog(`âŒ resumeRealtime error: ${e.message}`);
    }
  };

  // Ğ´ĞµĞ»Ğ°ĞµĞ¼ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğ¼ Ğ´Ğ»Ñ builtinHandlers
  window.pauseRoma = pauseRealtime;

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   *  Ğ¡Ñ‚Ğ°Ñ€Ñ‚
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
  const start = async () => {
    if (started) return;
    setStarted(true);
    addLog('â³ Loading configâ€¦');

    /* 1) prompt & tools ---------------------------------- */
    const [{ instructions }, { tools: userTools }] = await Promise.all([
      fetch('/2/get-assistant').then(r => r.json()),
      fetch('/2/get-tools').then(r => r.json())
    ]);

    const assistantTxt = (instructions || '').trim();
    addLog(`ğŸ”‘ Prompt: ${assistantTxt || '(empty)'}`);

    const hasQR   = userTools.some(f => f.name === 'show_qr_code');
    const hasStop = userTools.some(f => f.name === 'stop_roma');

    const tools = [
      ...userTools,
      ...(!hasQR && [{
        type       : 'function',
        name       : 'show_qr_code',
        description: 'ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ QRâ€‘ĞºĞ¾Ğ´',
        parameters : {
          type: 'object',
          properties: { qrUrl: { type: 'string' } },
          required: ['qrUrl']
        }
      }]),
      ...(!hasStop && [{
        type       : 'function',
        name       : 'stop_roma',
        description: 'Ğ£ÑÑ‹Ğ¿Ğ¸Ñ‚ÑŒ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ° (Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ wakeâ€‘listener)',
        parameters : { type: 'object', properties: {}, required: [] }
      }])
    ].flat();

    addLog('âœ… Config loaded');

    /* 2) WebSocket (signalling) --------------------------- */
    const loc   = window.location;
    const wsUrl = `${loc.protocol === 'https:' ? 'wss:' : 'ws:'}//${loc.host}${loc.pathname}ws`;
    const ws    = new WebSocket(wsUrl);
    wsRef.current = ws;

    ws.onopen  = () => addLog('ğŸ”Œ WS open');
    ws.onerror = () => addLog('âš ï¸ WS error');
    ws.onmessage = async ({ data }) => {
      const msg = JSON.parse(data);
      if (msg.type === 'answer') {
        addLog('â† SDP answer received');
        await pcRef.current.setRemoteDescription({ type: 'answer', sdp: msg.sdp });
      }
    };

    /* 3) RTCPeerConnection + Mic -------------------------- */
    const pc = new RTCPeerConnection({
      iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
    });
    pcRef.current = pc;

    const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const micTrack  = micStream.getAudioTracks()[0];
    senderRef.current = pc.addTrack(micTrack);
    addLog('ğŸ¤ Mic added to PC');

    pc.ontrack = e => {
      audioRef.current.srcObject = e.streams[0];
      addLog('ğŸ§ Remote audio stream attached');
      setIsSpeaking(true);
      setTimeout(() => setIsSpeaking(false), 1_500);
    };

    /* 4) DataChannel for OpenAI --------------------------- */
    const dc = pc.createDataChannel('oai-events');
    dcRef.current = dc;

    dc.onopen = () => {
      addLog('ğŸ“¡ DC open â€” sending session.update');

      const oaTools = tools.map(({ type, name, description, parameters }) => ({
        type, name, description, parameters
      }));

      dc.send(JSON.stringify({
        type: 'session.update',
        session: {
          instructions: assistantTxt,
          voice: 'alloy',
          turn_detection: { type: 'server_vad' },
          input_audio_transcription: { model: 'whisper-1' },
          output_audio_format: 'pcm16',
          modalities: ['text', 'audio'],
          tools: oaTools,
          tool_choice: 'auto'
        }
      }));

      // ÑÑ€Ğ°Ğ·Ñƒ Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ² "ÑĞ¿ÑÑ‰Ğ¸Ğ¹" Ñ€ĞµĞ¶Ğ¸Ğ¼
      pauseRealtime();
    };

    dc.onmessage = ({ data }) => {
      const ev = JSON.parse(data);

      /* function_call flow ------------------------------- */
      if (ev.type === 'response.output_item.added' && ev.item?.type === 'function_call') {
        pendingCallRef.current = { call_id: ev.item.call_id, name: ev.item.name, args: [] };
        return;
      }
      if (ev.type === 'response.function_call_arguments.delta' && pendingCallRef.current) {
        pendingCallRef.current.args.push(ev.delta || '');
        return;
      }
      if (ev.type === 'response.function_call_arguments.done' && pendingCallRef.current) {
        finishCall(dc, tools);
        return;
      }

      /* Ğ°Ğ½Ğ¸Ğ¼Ğ°Ñ†Ğ¸Ğ¸ / Ğ»Ğ¾Ğ³Ğ¸ --------------------------------- */
      if (ev.type === 'response.content_part.added') setIsSpeaking(true);

      if (ev.type === 'response.audio_transcript.delta') {
        const snippet = ev.delta.toLowerCase().trim();
        addLog(`ğŸ™ï¸ YOU: ${snippet}`);

        if (SLEEP_KEYWORDS.some(k => snippet.includes(k))) {
          addLog('ğŸ˜´ Voice cmd detected â€” going to sleep');
          pauseRealtime();
        }
      }

      if (ev.type === 'output_audio_buffer.stopped') setIsSpeaking(false);
    };

    /* 5) SDP handshake ----------------------------------- */
    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    addLog('â†’ Sending SDP offer');

    ws.onopen = () => ws.send(JSON.stringify({ type: 'offer', sdp: offer.sdp }));
  };

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   *  StopÂ â€” Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ disconnect
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
  const stop = () => {
    wakeRef.current?.stop();
    wakeRef.current = null;
    senderRef.current = null;

    dcRef.current?.close();
    pcRef.current?.close();
    wsRef.current?.close();

    setStarted(false);
    setIsSpeaking(false);
    addLog('ğŸ›‘ Stopped (full disconnect)');
  };

  /* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   *  UI
   * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€*/
  return (
    <div className="app-container">
      <img
        id="silent-avatar"
        src="/2/roma-silent.gif"
        className="avatar silent"
        style={{ zIndex: isSpeaking ? 0 : 1 }}
      />
      <img
        id="speak-avatar"
        src="/2/roma-speak.gif"
        className="avatar speaking"
        style={{ zIndex: isSpeaking ? 1 : 0 }}
      />

      {/* QRâ€‘ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° */}
      <img
        id="qr-img"
        src="/2/qr.png"
        alt="QR Code"
        style={{
          display: 'none',
          position: 'fixed',
          inset: 0,
          margin: 'auto',
          maxWidth: '60vmin',
          maxHeight: '60vmin',
          zIndex: 1_000,
          background: 'rgba(0,0,0,0.8)'
        }}
      />

     <div
   id="controls"
   style={{ display: hidden ? 'none' : 'block' }}   // <-- Ğ¿Ñ€ÑÑ‡ĞµĞ¼ Ğ²ÑÑ Ğ¿Ğ°Ğ½ĞµĞ»ÑŒ
 >




        <button onClick={start} disabled={started}>Start Talking</button>
        <button onClick={stop}   disabled={!started}>Stop</button>
        <button onClick={() => setHidden(!hidden)}>
          {hidden ? 'Show' : 'Hide'}
        </button>



        <div id="log">
          {log.map((t, i) => <p key={i}>{t}</p>)}
        </div>
      </div>

 {/* Ğ¿Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ‡Ğ½Ğ°Ñ Â«ShowÂ», Ğ²Ğ¸Ğ´Ğ½Ğ° Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸ ÑĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¹ Ğ¿Ğ°Ğ½ĞµĞ»Ğ¸ */}
      {hidden && (
        <button
          className="toggle-btn"
          onClick={() => setHidden(false)}
        >
          Show
        </button>
      )}

      <audio ref={audioRef} autoPlay style={{ display: 'none' }} />
    </div>
  );
}
